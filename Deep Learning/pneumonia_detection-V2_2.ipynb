{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3KDikoDwY8v"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VvxOowgOTndB"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib\n",
        "\n",
        "# Set the default figure size for matplotlib\n",
        "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3yEVbRlnlDf"
      },
      "source": [
        "# Load data and preprocess it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol59FQ2U-TTE"
      },
      "source": [
        "## Option 1:\n",
        "Download the dataset directly from the provided link. If this does not work, try Option **2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YVcGp51oUBlQ"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'http://vision.roboslang.org/open_datasets/pneumonia_dataset.zip'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kSeCVHn-hcF"
      },
      "source": [
        "## Option 2:\n",
        "If downloading the dataset from the link is too slow or the link is no longer working, download the dataset from Brigthspace, and upload it to the sample_data folder in Google Colab. For this, open the Files in the left hand side menu, and click the upload button, or drag and drop the archive in the folder you want. Depending on where you have copied this file, you might have to change the path below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7isqoqGosmiy"
      },
      "source": [
        "When you upload from the interface sometimes you don't get a lot of feedback for when the upload is done. You can also try to force the upload window to open by executing the below code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "KA_r7Q6Esaav",
        "outputId": "b9b50d3c-6820-4ea0-fcdf-1ecb9e3ba5a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c997c15-0b9c-446f-825a-fa2d864c49af\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c997c15-0b9c-446f-825a-fa2d864c49af\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7VzZUvK_DKA"
      },
      "outputs": [],
      "source": [
        "# For option 2, after you have copied the data locally, point the dataset_url to the local path\n",
        "\n",
        "dataset_url = '/content/sample_data/datasets/pneumonia_dataset.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbI-hk3Jq3v3"
      },
      "source": [
        "##Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rb1YuKutb6DA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee146b4-07d4-48fd-c148-87281eb14db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://vision.roboslang.org/open_datasets/pneumonia_dataset.zip\n",
            "86257778/86257778 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "out_path = '/content/sample_data/'\n",
        "archive = tf.keras.utils.get_file(origin=dataset_url, cache_dir='/content/sample_data/', extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0PjaJOFXbJ61"
      },
      "outputs": [],
      "source": [
        "# Create a 'pathlib.Path' object for the downloaded archive\n",
        "# Pathlib module offers classes representing filesystem paths with semantics\n",
        "# appropriate for different operating systems.\n",
        "data_dir = pathlib.Path(archive).with_suffix('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IxTLf2jbxe2",
        "outputId": "0c5b13ec-39d1-4225-aad0-d6c674a45406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "# Count the number of images in a specific directory\n",
        "image_count = len(list(data_dir.glob('./train/pneumonia/*.jpeg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qUU_NoKxtHp",
        "outputId": "8a94cfb7-13d8-44cd-c4c2-f56095c2b984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal training set - 100\n",
            "pneumonia training set - 100\n",
            "normal test set - 50\n",
            "pneumonia test set - 50\n"
          ]
        }
      ],
      "source": [
        "# Pneumonia dataset is split into train and test folders. Inside those folders you will\n",
        "# find additional folders: pneumonia and normal. You can explore the folders using\n",
        "# 'Files' tab from the right hand side.\n",
        "# How many images do we have in training for pneumonia? How many for normal CT scans?\n",
        "# How about in the testing set? How many for pneumonia and how many for normal scans?\n",
        "# Tip: use the len() function\n",
        "\n",
        "# print(data_dir)\n",
        "normtrain = len(list(data_dir.glob('./train/normal/*.jpeg')))\n",
        "print(\"normal training set -\", normtrain)\n",
        "pntrain = len(list(data_dir.glob('./train/pneumonia/*.jpeg')))\n",
        "print(\"pneumonia training set -\", pntrain)\n",
        "\n",
        "normtest = len(list(data_dir.glob('./test/pneumonia/*.jpeg')))\n",
        "print(\"normal test set -\", normtest)\n",
        "pntest = len(list(data_dir.glob('./test/pneumonia/*.jpeg')))\n",
        "print(\"pneumonia test set -\", pntest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wyaZFcvpxwL"
      },
      "outputs": [],
      "source": [
        "# 3. Display a pneumonia and a normal image from the testing dataset\n",
        "\n",
        "# Create a list of file paths for pneumonia images\n",
        "pneumonia_images = list(data_dir.glob('train/pneumonia/*'))\n",
        "# Open and display the first pneumonia image in the list\n",
        "PIL.Image.open(str(pneumonia_images[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtx3hXaEyqK4"
      },
      "outputs": [],
      "source": [
        "# Create a list of file paths for normal images\n",
        "normal_images = list(data_dir.glob('train/normal/*'))\n",
        "# Open and display the first normal image in the list\n",
        "PIL.Image.open(str(normal_images[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrEz4zkbE8yq"
      },
      "source": [
        "# Define a deep learning model that will learn the differences between pneumonia and normal CT images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AGncT3F_qGKe"
      },
      "outputs": [],
      "source": [
        "# Define batch size and image dimensions for training\n",
        "\n",
        "# The batch size is the number of samples processed before the model is updated.\n",
        "# Choose an appropriate batch size. Find out the resolution of the image and\n",
        "# fill in the values of the following three variables\n",
        "batch_size = 10\n",
        "img_height = 360\n",
        "img_width = 360"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-rwd_T8s0Exo"
      },
      "outputs": [],
      "source": [
        "train_data_dir  = os.path.join(data_dir,'train')\n",
        "test_data_dir = os.path.join(data_dir,'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6e8Dbw6p8fL",
        "outputId": "7f024248-8ca5-4efa-eec9-2fe6bb9db3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 files belonging to 2 classes.\n",
            "Using 160 files for training.\n"
          ]
        }
      ],
      "source": [
        "# Create a TensorFlow image dataset from a directory\n",
        "# Use the function tf.keras.utils.image_dataset_from_directory in order to load\n",
        "# the training dataset: https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
        "# 1. First argument is your training directory folder,\n",
        "# 2. Use 20% of the data for validation, for image size,\n",
        "# 3. name the subset as \"training\"\n",
        "# 4. you can set a seed such that when you repeat experiments you get similar results, eg: seed=123\n",
        "# 5. for image size use the img_height and img_width variables you defined previously.\n",
        "# 6. Use for batch size the batch_size variable you defined earlier in the code\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        " train_data_dir,\n",
        " validation_split=0.2,\n",
        " subset='training',\n",
        " seed=100,\n",
        " image_size=(img_height, img_width),\n",
        " batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2hI684wjqcHg"
      },
      "outputs": [],
      "source": [
        "# Create a layer to normalise pixel values to the [0, 1] range.\n",
        "# By default, when you load an image, each pixel value will have a value between 0-255\n",
        "# but, in neural networks, we need as input normalised values in [0,1] interval.\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxTxKXY5qhKK",
        "outputId": "4e722426-a362-466b-8bb6-dab8daea954f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0 tf.Tensor([0.26820263 0.26820263 0.26820263], shape=(3,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image), first_image[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wXebzJrEqm7K"
      },
      "outputs": [],
      "source": [
        "# Define the number of classes in the classification problem.\n",
        "# How many classes do we have in this dataset?\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wm-uZPDWqlR9"
      },
      "outputs": [],
      "source": [
        "from keras.src.layers.serialization import activation\n",
        "# Define a tensorflow model using the tf.keras.Sequential class: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "# The last layer should be a Dense layer with the number of output neurons num_classes\n",
        "# Use as a starting point the tf.keras.Sequential model defined for the MNIST problem.\n",
        "# See Lab-DeepLearning-ImageClassification.\n",
        "# For the first Conv2D layer, you are not required to specify the input shape. If that\n",
        "# parameter is not given, tensorflow library will infer the size of the input when\n",
        "# you fit the model, so it will depend on the size of the dataset.\n",
        "# Important: change the output of the last Dense layer to match the number of classes for this problem.\n",
        "# If you don't use any of the Dropout layers what accuracy do you get?\n",
        "# What accuracy do you get with the Dropout layers?\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(img_height, img_width, 3)),\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu'), # numbers 16, 32, 64 represent no filters\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax), #softmax ensures the scores max sum to 1\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mJ_tuSyzquN1"
      },
      "outputs": [],
      "source": [
        "# Compile the model with an optimizer, loss function, and evaluation metric\n",
        "# There are several ways in which the loss or error between the label and\n",
        "# the predictions can be computed. One of them is called SparseCategoricalCrossentropy\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
        "# You can also experiment with BinaryCrossentropy since for this problem we also have\n",
        "# two classes, pneumonia vs normal: https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  #loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), - using this loss function caps accuracy at 50\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy']) # Monitor accuracy and F1 score during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg9ymuSlqwYI",
        "outputId": "b3cd9a25-f260-4e4c-f4d3-9bd8977e521b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 3s 59ms/step - loss: 384.4716 - accuracy: 0.4875\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 2s 59ms/step - loss: 5.6592 - accuracy: 0.7063\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 3s 112ms/step - loss: 0.7166 - accuracy: 0.8687\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 2s 65ms/step - loss: 0.2860 - accuracy: 0.9688\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 2s 62ms/step - loss: 0.0650 - accuracy: 0.9688\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 2s 62ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 2s 57ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 2s 87ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 3s 103ms/step - loss: 9.1029e-04 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 2s 70ms/step - loss: 5.9632e-04 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - 3s 103ms/step - loss: 3.5171e-04 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - 3s 103ms/step - loss: 1.9312e-04 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - 4s 164ms/step - loss: 6.4591e-04 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "16/16 [==============================] - 3s 87ms/step - loss: 8.7833e-05 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "16/16 [==============================] - 3s 101ms/step - loss: 4.6261e-05 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c64a70aa320>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Train the model on the provided dataset for a specified number of epochs\n",
        "# Modify the network architecture such that you maximise the accuracy.\n",
        "# Tip: aim to get an accuracy of at least 90% on the training set.\n",
        "# For this, you can use the function fit, as in model.fit(...)\n",
        "# The first argument is the train_ds variable defined above.\n",
        "# This variable contains both the x (data - pneumonia and normal images) and y\n",
        "# (labels - pneumonia vs normal).\n",
        "# Start training using 5 epochs. What is the accuracy you get?\n",
        "# How about if you increase the number of epochs?\n",
        "model.fit(train_ds, epochs=15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaRpL01W4u_2",
        "outputId": "8eb0d609-a482-4596-da34-04efb9eaf183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Let's load the testing dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2D3V6r55SGe",
        "outputId": "22ba8bdd-7eaa-4399-9dd3-0d65e3b228e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 27ms/step - loss: 1.9565 - accuracy: 0.7000\n",
            "Model accuracy on the test set is: [1.956466555595398, 0.699999988079071]\n"
          ]
        }
      ],
      "source": [
        "# What is the loss and accuracy on the Testing dataset?\n",
        "# Tip: instead of (x_test, y_test) we used in the lab last week, you can use\n",
        "# directly test_ds which contains both data and labels\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n",
        "# eg: model.evaluate(...)\n",
        "# You only need to specify the testing dataset.\n",
        "print(\"Model accuracy on the test set is:\", model.evaluate(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO9Z1pqy6M9i"
      },
      "outputs": [],
      "source": [
        "# Try to improve the model such that it performs well on both training and testing datasets."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2kSeCVHn-hcF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}