{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "J3KDikoDwY8v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvxOowgOTndB"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib\n",
        "\n",
        "# Set the default figure size for matplotlib\n",
        "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data and preprocess it"
      ],
      "metadata": {
        "id": "y3yEVbRlnlDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1:\n",
        "Download the dataset directly from the provided link. If this does not work, try Option **2**"
      ],
      "metadata": {
        "id": "ol59FQ2U-TTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVcGp51oUBlQ"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'http://vision.roboslang.org/open_datasets/pneumonia_dataset.zip'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2:\n",
        "If downloading the dataset from the link is too slow or the link is no longer working, download the dataset from Brigthspace, and upload it to the sample_data folder in Google Colab. For this, open the Files in the left hand side menu, and click the upload button, or drag and drop the archive in the folder you want. Depending on where you have copied this file, you might have to change the path below.\n",
        "\n"
      ],
      "metadata": {
        "id": "2kSeCVHn-hcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you upload from the interface sometimes you don't get a lot of feedback for when the upload is done. You can also try to force the upload window to open by executing the below code."
      ],
      "metadata": {
        "id": "7isqoqGosmiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "KA_r7Q6Esaav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For option 2, after you have copied the data locally, point the dataset_url to the local path\n",
        "\n",
        "dataset_url = '/content/sample_data/datasets/pneumonia_dataset.zip'"
      ],
      "metadata": {
        "id": "l7VzZUvK_DKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocess the data"
      ],
      "metadata": {
        "id": "mbI-hk3Jq3v3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb1YuKutb6DA"
      },
      "outputs": [],
      "source": [
        "out_path = '/content/sample_data/'\n",
        "archive = tf.keras.utils.get_file(origin=dataset_url, cache_dir='/content/sample_data/', extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PjaJOFXbJ61"
      },
      "outputs": [],
      "source": [
        "# Create a 'pathlib.Path' object for the downloaded archive\n",
        "# Pathlib module offers classes representing filesystem paths with semantics\n",
        "# appropriate for different operating systems.\n",
        "data_dir = pathlib.Path(archive).with_suffix('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IxTLf2jbxe2"
      },
      "outputs": [],
      "source": [
        "# Count the number of images in a specific directory\n",
        "image_count = len(list(data_dir.glob('./train/pneumonia/*.jpeg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN YOUR CODE HERE\n",
        "\n",
        "# Pneumonia dataset is split into train and test folders. Inside those folders you will\n",
        "# find additional folders: pneumonia and normal. You can explore the folders using\n",
        "# 'Files' tab from the right hand side.\n",
        "# How many images do we have in training for pneumonia? How many for normal CT scans?\n",
        "# How about in the testing set? How many for pneumonia and how many for normal scans?\n",
        "# Tip: use the len() function\n",
        "\n",
        "\n",
        "\n",
        "# END YOUR CODE HERE"
      ],
      "metadata": {
        "id": "2qUU_NoKxtHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wyaZFcvpxwL"
      },
      "outputs": [],
      "source": [
        "# Create a list of file paths for pneumonia images\n",
        "pneumonia_images = list(data_dir.glob('train/pneumonia/*'))\n",
        "# Open and display the first pneumonia image in the list\n",
        "PIL.Image.open(str(pneumonia_images[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN YOUR CODE HERE\n",
        "\n",
        "# 3. Display a pneumonia and a normal image from the testing dataset\n",
        "# Create a list of file paths for pneumonia images\n",
        "\n",
        "# Open and display the first pneumonia image in the list\n",
        "\n",
        "# END YOUR CODE HERE"
      ],
      "metadata": {
        "id": "qtx3hXaEyqK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a deep learning model that will learn the differences between pneumonia and normal CT images\n"
      ],
      "metadata": {
        "id": "jrEz4zkbE8yq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGncT3F_qGKe"
      },
      "outputs": [],
      "source": [
        "# Define batch size and image dimensions for training\n",
        "\n",
        "# BEGIN YOUR CODE HERE\n",
        "# The batch size is the number of samples processed before the model is updated.\n",
        "# Choose an appropriate batch size. Find out the resolution of the image and\n",
        "# fill in the values of the following three variables\n",
        "# batch_size = TODO\n",
        "# img_height = TODO\n",
        "# img_width = TODO\n",
        "\n",
        "\n",
        "# END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir  = os.path.join(data_dir,'train')\n",
        "test_data_dir = os.path.join(data_dir,'test')"
      ],
      "metadata": {
        "id": "-rwd_T8s0Exo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6e8Dbw6p8fL"
      },
      "outputs": [],
      "source": [
        "# Create a TensorFlow image dataset from a directory\n",
        "# BEGIN YOUR CODE HERE\n",
        "# Use the function tf.keras.utils.image_dataset_from_directory in order to load\n",
        "# the training dataset: https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
        "# 1. First argument is your training directory folder,\n",
        "# 2. Use 20% of the data for validation, for image size,\n",
        "# 3. name the subset as \"training\"\n",
        "# 4. you can set a seed such that when you repeat experiments you get similar results, eg: seed=123\n",
        "# 5. for image size use the img_height and img_width variables you defined previously.\n",
        "# 6. Use for batch size the batch_size variable you defined earlier in the code\n",
        "# tf.keras.utils.image_dataset_from_directory(\n",
        "#     directory,\n",
        "#     validation_split=None,\n",
        "#     subset='',\n",
        "#     seed=None,\n",
        "#     image_size=(height, width),\n",
        "#     batch_size=-1\n",
        "# )\n",
        "# eg: train_ds = tf.keras.utils.image_dataset_from_directory(...)\n",
        "\n",
        "\n",
        "# END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hI684wjqcHg"
      },
      "outputs": [],
      "source": [
        "# Create a layer to normalise pixel values to the [0, 1] range.\n",
        "# By default, when you load an image, each pixel value will have a value between 0-255\n",
        "# but, in neural networks, we need as input normalised values in [0,1] interval.\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxTxKXY5qhKK"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image), first_image[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXebzJrEqm7K"
      },
      "outputs": [],
      "source": [
        "# BEGIN YOUR CODE HERE\n",
        "# Define the number of classes in the classification problem.\n",
        "# How many classes do we have in this dataset?\n",
        "# num_classes = TODO\n",
        "\n",
        "# END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm-uZPDWqlR9"
      },
      "outputs": [],
      "source": [
        "# BEGIN YOUR CODE HERE\n",
        "# Define a tensorflow model using the tf.keras.Sequential class: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "# The last layer should be a Dense layer with the number of output neurons num_classes\n",
        "# Use as a starting point the tf.keras.Sequential model defined for the MNIST problem.\n",
        "# See Lab-DeepLearning-ImageClassification.\n",
        "# For the first Conv2D layer, you are not required to specify the input shape. If that\n",
        "# parameter is not given, tensorflow library will infer the size of the input when\n",
        "# you fit the model, so it will depend on the size of the dataset.\n",
        "# Important: change the output of the last Dense layer to match the number of classes for this problem.\n",
        "# If you don't use any of the Dropout layers what accuracy do you get?\n",
        "# What accuracy do you get with the Dropout layers?\n",
        "\n",
        "\n",
        "\n",
        "# END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ_tuSyzquN1"
      },
      "outputs": [],
      "source": [
        "# Compile the model with an optimizer, loss function, and evaluation metric\n",
        "# There are several ways in which the loss or error between the label and\n",
        "# the predictions can be computed. One of them is called SparseCategoricalCrossentropy\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
        "# You can also experiment with BinaryCrossentropy since for this problem we also have\n",
        "# two classes, pneumonia vs normal: https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy']) # Monitor accuracy and F1 score during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg9ymuSlqwYI"
      },
      "outputs": [],
      "source": [
        "# BEGIN YOUR CODE HERE\n",
        "# Train the model on the provided dataset for a specified number of epochs\n",
        "# Modify the network architecture such that you maximise the accuracy.\n",
        "# Tip: aim to get an accuracy of at least 90% on the training set.\n",
        "# For this, you can use the function fit, as in model.fit(...)\n",
        "# The first argument is the train_ds variable defined above.\n",
        "# This variable contains both the x (data - pneumonia and normal images) and y\n",
        "# (labels - pneumonia vs normal).\n",
        "# Start training using 5 epochs. What is the accuracy you get?\n",
        "# How about if you increase the number of epochs?\n",
        "\n",
        "# END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the testing dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "VaRpL01W4u_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN YOUR CODE HERE\n",
        "# What is the loss and accuracy on the Testing dataset?\n",
        "# Tip: instead of (x_test, y_test) we used in the lab last week, you can use\n",
        "# directly test_ds which contains both data and labels\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n",
        "# eg: model.evaluate(...)\n",
        "# You only need to specify the testing dataset.\n",
        "\n",
        "\n",
        "# END YOUR CODE HERE"
      ],
      "metadata": {
        "id": "c2D3V6r55SGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to improve the model such that it performs well on both training and testing datasets."
      ],
      "metadata": {
        "id": "JO9Z1pqy6M9i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}